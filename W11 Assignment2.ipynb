{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8637c4d8-0a92-4aff-9a73-ca1fcde17af0",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example\n",
    "Probability Mass Function (PMF)\n",
    "\n",
    "PMF stands for Probability Mass Function. It is a mathematical function that describes the probability distribution of a discrete random variable.\n",
    "The PMF of a discrete random variable assigns a probability to each possible value of the random variable. The probabilities assigned by the PMF must satisfy two conditions:\n",
    "a. The probability assigned to each value must be non-negative (i.e., greater than or equal to zero).\n",
    "b. The sum of the probabilities assigned to all possible values must equal 1.\n",
    "A probability mass function (PMF) is a function that gives the probability that a discrete random variable is exactly equal to a certain value. It maps each possible value of the discrete random variable to a probability. The PMF is represented as a histogram-like bar graph, where the x-axis represents the possible outcomes and the y-axis represents their corresponding probabilities.\n",
    "The PMF is the discrete analogue of the probability density function (PDF), which is used for continuous random variables. The PDF represents the density of the probability distribution, and the area under the curve of the PDF between two points represents the probability of the random variable taking a value within that range.\n",
    "In the case of the probability mass function (PMF), if a point on the x-axis represents a specific value of a discrete random variable X, and the corresponding point on the y-axis represents the probability of X taking that value, then we can say that the probability of X taking that specific value is equal to the y-coordinate of that point.\n",
    "On the other hand, in the case of the cumulative distribution function (CDF), if a point on the x-axis represents a specific value of a random variable X, then the corresponding point on the y-axis represents the probability of X being less than or equal to that value. Therefore, we can say that the probability of X being less than or equal to that specific value is equal to the y-coordinate of that point on the CDF.\n",
    "Examples of probability density functions (PDFs) are:\n",
    "a. The normal distribution PDF, which is a bell-shaped curve that is symmetric about the mean and has a fixed variance. It is commonly used to model natural phenomena such as heights, weights, and test scores.\n",
    "\n",
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?\n",
    "\n",
    "The Cumulative Distribution Function (CDF), of a real-valued random variable X, evaluated at x, is the probability function that X will take a value less than or equal to x. It is used to describe the probability distribution of random variables in a table. And with the help of these data, we can easily create a CDF plot in an excel sheet.\n",
    "In other words, CDF finds the cumulative probability for the given value. To determine the probability of a random variable, it is used and also to compare the probability between values under certain conditions. For discrete distribution functions, CDF gives the probability values till what we specify and for continuous distribution functions, it gives the area under the probability density function up to the given value specified.\n",
    "Cumulative Distribution Function Applications\n",
    "The most important application of cumulative distribution function is used in statistical analysis. In statistical analysis, the concept of CDF is used in two ways.\n",
    "•\tFinding the frequency of occurrence of values for the given phenomena using cumulative frequency analysis.\n",
    "•\tTo derive some simple statistics properties, by using an empirical distribution function, that uses a formal direct estimate of CDFs.\n",
    "\n",
    "Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution.\n",
    "\n",
    "Normal distribution, also known as the Gaussian distribution, is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent in occurrence than data far from the mean. The normal distribution appears as a \"bell curve\" when graphed.\n",
    "The normal distribution is the most common type of distribution assumed in technical stock market analysis. The standard normal distribution has two parameters: the mean and the standard deviation. In a normal distribution, mean (average), median (midpoint), and mode (most frequent observation) are equal. These values represent the peak or highest point. The distribution then falls symmetrically around the mean, the width of which is defined by the standard deviation.\n",
    "The normal distribution model is key to the Central Limit Theorem (CLT) which states that averages calculated from independent, identically distributed random variables have approximately normal distributions, regardless of the type of distribution from which the variables are sampled.1\n",
    "The normal distribution is one type of symmetrical distribution. Symmetrical distributions occur when a dividing line produces two mirror images. Not all symmetrical distributions are normal since some data could appear as two humps or a series of hills in addition to the bell curve that indicates a normal distribution.\n",
    "Skewness\n",
    "Skewness measures the degree of symmetry of a distribution. The normal distribution is symmetric and has a skewness of zero. If the distribution of a data set instead has a skewness less than zero, or negative skewness (left-skewness), then the left tail of the distribution is longer than the right tail; positive skewness (right-skewness) implies that the right tail of the distribution is longer than the left.\n",
    "Kurtosis\n",
    "Kurtosis measures the thickness of the tail ends of a distribution to the tails of a distribution. The normal distribution has a kurtosis equal to 3.0. Distributions with larger kurtosis greater than 3.0 exhibit tail data exceeding the tails of the normal distribution (e.g., five or more standard deviations from the mean).\n",
    "This excess kurtosis is known in statistics as leptokurtic, but is more colloquially known as \"fat tails.\" The occurrence of fat tails in financial markets describes what is known as tail risk. Distributions with low kurtosis less than 3.0 (platykurtic) exhibit tails that are generally less extreme (\"skinnier\") than the tails of the normal distribution.\n",
    "Many naturally occurring phenomena appear to be normally distributed. For example, the average height of a human is roughly 175 cm (5' 9\"), counting both males and females.\n",
    "As the chart below shows, most people conform to that average. Taller and shorter people exist with decreasing frequency in the population. According to the empirical rule, 99.7% of all people will fall with +/- three standard deviations of the mean, or between 154 cm (5' 0\") and 196 cm (6' 5\"). Those taller and shorter than this would be rare (just 0.15% of the population each).\n",
    "\n",
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution. \n",
    "\n",
    "Example 1: Birthweight of Babies\n",
    "It’s well-documented that the birthweight of newborn babies is normally distributed with a mean of about 7.5 pounds.\n",
    "The histogram of the birthweight of newborn babies in the U.S. displays a bell-shape that is typically of the normal distribution:\n",
    "Example 2: Shoe Sizes\n",
    "The distribution of shoe sizes for males in the U.S. is roughly normally distributed with a mean of size 10 and a standard deviation of 1.\n",
    "A histogram of the shoe sizes of all U.S. male reveals a bell shape with a single peak at size 10:\n",
    "\n",
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?\n",
    "\n",
    "Bernoulli Distribution!\n",
    "This distribution deals with the data which only has 1 trial & only 2 possible outcomes. Anything other than that will not fall under the Bernoulli Distribution category.\n",
    "Example of Bernoulli Distribution!\n",
    "For the real-life example, let’s consider the situation of passing or failing an exam. Let’s assume the probability to pass the exam is 95%, therefore the probability to fail will be 5%.\n",
    "In this case, if the event to pass the exam is considered, then the Bernoulli event will contain the probability of passing the exam. Similarly, it goes for failing the exam.\n",
    "Binomial Distribution!\n",
    "It is the collection of Bernoulli trials for the same event, i.e., it contains more than 1 Bernoulli event for the same scenario for which the Bernoulli trial is calculated.\n",
    "Example of Binomial Distribution!\n",
    "Considering the same example of the Bernoulli Distribution, let’s create Binomial Distribution from that example.\n",
    "Considering 95% & 5% for passing & failing an exam for a student respectively. If we want to calculate the probability of a student to pass exactly 5 exams out of 5 exams in which it appeared, using the above probability formula it can be easily calculated.\n",
    "Binomial VS Bernoulli Keypoints!\n",
    "Bernoulli deals with the outcome of the single trial of the event, whereas Binomial deals with the outcome of the multiple trials of the single event.\n",
    "Bernoulli is used when the outcome of an event is required for only one time, whereas the Binomial is used when the outcome of an event is required multiple times.\n",
    "\n",
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations.\n",
    "\n",
    "Here we need to determine the value of Z=x−μσ\n",
    "Here, μ=Mean=50 and σ=Stand Deviation=10\n",
    "For, x=50⇒Z=50−50/4=0\n",
    "For, x=60⇒Z=60−50/4=2.5\n",
    "⇒P(50<x<60)=P(0<Z<2.5)\n",
    "⇒P(0<Z<2.5)=P(Z<2.5)−P(Z<0) (∵P(a<Z<b)=P(Z<b)−P(Z<a))\n",
    "\n",
    "Q7: Explain uniform Distribution with an example.\n",
    "\n",
    "In statistics, uniform distribution refers to a type of probability distribution in which all outcomes are equally likely. Probability distributions can help you decide the probability of a future event.\n",
    "Uniform distribution for a deck of cards is expected because the likelihood of drawing a heart, a club, a diamond, or a spade is equally likely. A coin also has a uniform distribution expectation because the odds of getting either heads or tails (front or back of the coin) in a coin toss are the same.\n",
    "Example of Uniform Distribution\n",
    "There are 52 cards in a traditional deck of cards. Also in that deck are four suits: hearts, diamonds, clubs, and spades. Each suit contains an A, 2, 3, 4, 5, 6, 7, 8, 9, 10, J, Q, K. The deck contains 2 jokers, as well. However, we'll ignore the jokers and face cards for this example, and focus only on number cards replicated in each suit. As a result, we are left with 40 cards, a set of discrete data.\n",
    "Suppose you want to know the probability of pulling a 2 of hearts from the modified deck. The probability of pulling a 2 of hearts is 1/40 or 2.5%. Each card is unique; therefore, the likelihood that you will pull any one of the cards in the deck is the same.\n",
    "Now, let's consider the likelihood of pulling a heart from the deck. The probability is significantly higher. Why? We are now only concerned with the suits in the deck. Since there are only four suits, pulling a heart yields a probability of 1/4 or 25%.\n",
    "\n",
    "Q8: What is the z score? State the importance of the z score.\n",
    "\n",
    "Z-score is a statistical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. In investing and trading, Z-scores are measures of an instrument's variability and can be used by traders to help determine volatility.\n",
    "A z-score is important because it tells where your data lies in the data distribution. For example, if a z-score is 1.5, it is 1.5 standard deviations away from the mean. Because 68% of your data lies within one standard deviation (if it is normally distributed), 1.5 might be considered too far from average for your comfort.\n",
    "\n",
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem.\n",
    "\n",
    "In probability theory, the central limit theorem (CLT) states that the distribution of a sample variable approximates a normal distribution (i.e., a “bell curve”) as the sample size becomes larger, regardless of the population's actual distribution shape. The central limit theorem (CLT) states that the distribution of sample means approximates a normal distribution as the sample size gets larger, regardless of the population's distribution.\n",
    "Sample sizes equal to or greater than 30 are often considered sufficient for the CLT to hold.\n",
    "Why Is the Central Limit Theorem Useful?\n",
    "The central limit theorem is useful when analyzing large data sets because it allows one to assume that the sampling distribution of the mean will be normally-distributed in most cases. This allows for easier statistical analysis and inference. For example, investors can use central limit theorem to aggregate individual security performance data and generate distribution of sample means that represent a larger population distribution for security returns over a period of time.\n",
    "\n",
    "Q10: State the assumptions of the Central Limit Theorem.\n",
    "\n",
    "Central Limit Theorem Statement\n",
    "The central limit theorem states that whenever a random sample of size n is taken from any distribution with mean and variance, then the sample mean will be approximately a normal distribution with mean and variance. The larger the value of the sample size, the better the approximation of the normal.\n",
    "\n",
    "Assumptions of the Central Limit Theorem\n",
    "•\tThe sample should be drawn randomly following the condition of randomisation.\n",
    "•\tThe samples drawn should be independent of each other. They should not influence the other samples.\n",
    "•\tWhen the sampling is done without replacement, the sample size shouldn’t exceed 10% of the total population.\n",
    "•\tThe sample size should be sufficiently large.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
